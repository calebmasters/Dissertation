{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF to txt\n",
    "libraries = `pip install PyPDF2 pytesseract pillow pdf2image`\n",
    "* Tesseract ocr needs to be set up and added to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfdir = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/converttxt'\n",
    "txtdir = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/txtconvertednew'\n",
    "txtolddir = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/speeches/txtold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def convert_pdf_to_text(path):\n",
    "    text_content = []\n",
    "    pdf_file_obj = open(path, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
    "\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        try:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                text_content.append(text)\n",
    "            else:\n",
    "                raise ValueError(\"No text found, use OCR.\")\n",
    "        except:\n",
    "            # Fallback to OCR for scanned/image-based PDF pages\n",
    "            images = convert_from_path(path, first_page=page_num+1, last_page=page_num+1)\n",
    "            for image in images:\n",
    "                text = pytesseract.image_to_string(image, lang='eng', output_type=Output.STRING)\n",
    "                text_content.append(text)\n",
    "\n",
    "    pdf_file_obj.close()\n",
    "    return \"\\n\".join(text_content)\n",
    "\n",
    "# Specify the directory containing PDFs\n",
    "pdf_directory = pdfdir\n",
    "output_directory = txtdir\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Convert each PDF to a text file\n",
    "for pdf_file in os.listdir(pdf_directory):\n",
    "    if pdf_file.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(pdf_directory, pdf_file)\n",
    "        output_text = convert_pdf_to_text(pdf_path)\n",
    "        text_filename = os.path.join(output_directory, os.path.splitext(pdf_file)[0] + '.txt')\n",
    "        with open(text_filename, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(output_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unconverted PDF files:\n",
      "23NANA630408\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_unconverted_pdfs(pdf_directory, txt_directory):\n",
    "    # Get a set of PDF filenames without extension\n",
    "    pdf_files = {os.path.splitext(file)[0] for file in os.listdir(pdf_directory) if file.endswith('.pdf' or '.docx')}\n",
    "    \n",
    "    # Get a set of text filenames without extension\n",
    "    txt_files = {os.path.splitext(file)[0] for file in os.listdir(txt_directory) if file.endswith('.txt' or '.rtf' or '')}\n",
    "    \n",
    "    # Find PDF files that don't have a corresponding text file\n",
    "    unconverted_pdfs = pdf_files - txt_files\n",
    "    \n",
    "    return unconverted_pdfs\n",
    "\n",
    "# Specify the directories containing PDFs and text files\n",
    "pdf_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/PDF'\n",
    "output_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/txt'\n",
    "\n",
    "# Find unconverted PDFs\n",
    "unconverted_pdfs = find_unconverted_pdfs(pdf_directory, output_directory)\n",
    "\n",
    "# Print or handle the unconverted PDFs\n",
    "if unconverted_pdfs:\n",
    "    print(\"Unconverted PDF files:\")\n",
    "    for pdf in unconverted_pdfs:\n",
    "        print(pdf)\n",
    "else:\n",
    "    print(\"All PDF files have been converted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the directory: 351609 bytes\n",
      "Total number of files: 67\n",
      "Total size of the directory: 14194354 bytes\n",
      "Total number of files: 67\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to get the size of a directory\n",
    "def get_dir_size(dir):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(dir):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "# Function to count the number of files in a directory\n",
    "def count_files(dir):\n",
    "    count = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(dir):\n",
    "        count += len(filenames)\n",
    "    return count\n",
    "\n",
    "def count_directory(directory_path):\n",
    "    if __name__ == '__main__':\n",
    "        directory = directory_path\n",
    "        if not os.path.exists(directory):\n",
    "            print(\"Directory does not exist!\")\n",
    "            exit()\n",
    "\n",
    "        # Get the size of the directory\n",
    "        dir_size = get_dir_size(directory)\n",
    "        print(f\"Total size of the directory: {dir_size} bytes\")\n",
    "\n",
    "        # Count the number of files in the directory\n",
    "        file_count = count_files(directory)\n",
    "        print(f\"Total number of files: {file_count}\")\n",
    "\n",
    "count_directory('/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/To be translated/French/txt')\n",
    "count_directory('/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/To be translated/French/pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "csv_path = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/UNFCCC.csv'  # Update this path to your CSV file location\n",
    "source_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/PDF'  # Update this to your source directory\n",
    "# source_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/txt'  # Update this to your source directory\n",
    "destination_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/Translations/originals all/pdf'  # Update this to your destination directory\n",
    "# destination_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/Translations/Other/txt'\n",
    "# destination_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/Translations/Other/pdf'\n",
    "\n",
    "\n",
    "\n",
    "# User input for filtering\n",
    "column_name = 'Language'\n",
    "match_value = 'ur' #Leave blank for any\n",
    "\n",
    "# Read CSV file\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"CSV file not found: {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "try:\n",
    "    os.makedirs(destination_directory, exist_ok=True)\n",
    "except FileExistsError:\n",
    "    print(f\"Destination directory already exists: {destination_directory}\")\n",
    "    exit()\n",
    "\n",
    "# Extensions to check\n",
    "extensions = ['.pdf', '.docx', '.txt', 'rtf']\n",
    "\n",
    "# Filter the CSV data\n",
    "if column_name in df.columns:\n",
    "    if match_value:\n",
    "        df = df[df[column_name] == match_value]\n",
    "    else:\n",
    "        df = df[df[column_name].notna()]\n",
    "\n",
    "# Copy files\n",
    "for index, row in df.iterrows():\n",
    "    base_file_name = row['File Name']\n",
    "    found = False\n",
    "\n",
    "    # Check each extension\n",
    "    for ext in extensions:\n",
    "        file_name = f\"{base_file_name}{ext}\"\n",
    "        source_path = os.path.join(source_directory, file_name)\n",
    "        if os.path.exists(source_path):\n",
    "            try:\n",
    "                shutil.copy(source_path, destination_directory)\n",
    "                found = True\n",
    "            except:\n",
    "                print(f\"Error copying file: {file_name}\")\n",
    "                continue\n",
    "            break  # Stop checking other extensions if file is found\n",
    "\n",
    "    if not found:\n",
    "        print(f\"File not found for any expected extensions: {base_file_name}\")\n",
    "\n",
    "print(\"Files copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting and moving pdfs removed from dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Copied and deleted: COP27 Botswana.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Operation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "csv_path = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/UNFCCC.csv'  # Update this path to your CSV file location\n",
    "source_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/txt'  # Update this to your source directory\n",
    "destination_directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/Ommitted txt'  # Update this to your destination directory\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "file_names_from_csv = df['File Name'].apply(lambda x: os.path.splitext(x)[0]).tolist()\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over all files in the source directory\n",
    "for file in os.listdir(source_directory):\n",
    "    base_name = os.path.splitext(file)[0]  # Get the base file name without extension\n",
    "\n",
    "    # Check if the base name of the file is not in the list from the CSV\n",
    "    if base_name not in file_names_from_csv:\n",
    "        source_path = os.path.join(source_directory, file)\n",
    "        destination_path = os.path.join(destination_directory, file)\n",
    "\n",
    "        # Copy and then delete the file\n",
    "        shutil.copy(source_path, destination_path)\n",
    "        os.remove(source_path)\n",
    "        print(f\"Copied and deleted: {file}\")\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "print(\"Operation completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining PDF's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20mb limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "def combine_pdfs_with_size_limit(directory_path, max_size_mb=20):\n",
    "    # Initialize variables\n",
    "    max_size = max_size_mb * 1024 * 1024  # Convert MB to bytes\n",
    "    output_index = 1\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    # Function to write and reset the writer\n",
    "    def write_and_reset(writer, index):\n",
    "        output_filename = f'combined_{index}.pdf'\n",
    "        with open(output_filename, 'wb') as output_pdf:\n",
    "            writer.write(output_pdf)\n",
    "        return PdfWriter(), index + 1\n",
    "\n",
    "    # List all PDF files\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]\n",
    "    files.sort()  # Optional: Sort files if needed\n",
    "\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Read the PDF file\n",
    "        reader = PdfReader(file_path)\n",
    "        \n",
    "        # Temporary memory buffer to estimate the file size\n",
    "        temp_buffer = io.BytesIO()\n",
    "\n",
    "        # Add pages individually and write to the buffer to estimate size\n",
    "        for page in reader.pages:\n",
    "            writer.add_page(page)\n",
    "            writer.write(temp_buffer)\n",
    "\n",
    "            # Check if the file size exceeds the limit\n",
    "            if temp_buffer.tell() > max_size:\n",
    "                # Finalize the current PDF and start a new one\n",
    "                writer, output_index = write_and_reset(writer, output_index)\n",
    "                # Reset buffer\n",
    "                temp_buffer = io.BytesIO()\n",
    "                # Add the current page to the new writer\n",
    "                writer.add_page(page)\n",
    "                writer.write(temp_buffer)\n",
    "\n",
    "    # Write the last set of combined PDFs if any pages have been added\n",
    "    if len(writer.pages) > 0:\n",
    "        write_and_reset(writer, output_index)\n",
    "\n",
    "# Usage example\n",
    "directory_path = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/To be translated/Arabic'\n",
    "combine_pdfs_with_size_limit(directory_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'combined_1.pdf' with files: ['18AlgeriaCOP24186330.pdf', '18KuwaitCOP24186437.pdf', '18OmanCOP24185051.pdf', '18TunisiaCOP24186404.pdf', '19AlgeriaCOP25204579.pdf', '19BahrainCOP25204114.pdf', '19KuwaitCOP25204061.pdf']\n",
      "Created 'combined_2.pdf' with files: ['19MoroccoCOP25204069.pdf', '21AlgeriaCOP26310802.pdf', '21KuwaitCOP26309209.pdf', '21NACOP26309286.pdf', '21OmanCOP26310839.pdf']\n",
      "Created 'combined_3.pdf' with files: ['21QatarCOP26310872.pdf', '21SyriaCOP26310880.pdf', '21TunisiaCOP26310884.pdf', '22AlgeriaCOP27622747.pdf', '22BahrainCOP27623882.pdf', '22LebanonCOP27624199.pdf', '22NACOP27623385.pdf', '22NACOP27624084.pdf', '22OmanCOP27623899.pdf', '22QatarCOP27623900.pdf', '22SudanCOP27624198.pdf', '22YemenCOP27623027.pdf', '23BahrainCOP28636641.pdf', '23KyrgyzstanCOP28636282.pdf']\n",
      "Created 'combined_4.pdf' with files: ['23LibyaCOP28636285.pdf', '23NACOP28634579.pdf', '23NACOP28635860.pdf', '23NACOP28636637.pdf', '23OmanCOP28636628.pdf', '23QatarCOP28636633.pdf', '23SyriaCOP28635631.pdf', '23TunisiaCOP28636639.pdf', '24KuwaitCOP28637243.pdf', '24SaudiArabiaCOP28637245.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "def combine_pdfs_with_size_limit(directory_path, max_size_mb=20):\n",
    "    # Initialize variables\n",
    "    max_size = max_size_mb * 1024 * 1024  # Convert MB to bytes\n",
    "    output_index = 1\n",
    "    writer = PdfWriter()\n",
    "    current_file_list = []  # List to keep track of files in the current combination\n",
    "\n",
    "    # Function to write and reset the writer\n",
    "    def write_and_reset(writer, index, file_list):\n",
    "        output_filename = f'combined_{index}.pdf'\n",
    "        with open(output_filename, 'wb') as output_pdf:\n",
    "            writer.write(output_pdf)\n",
    "        print(f\"Created '{output_filename}' with files: {file_list}\")\n",
    "        return PdfWriter(), index + 1, []\n",
    "\n",
    "    # List all PDF files\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]\n",
    "    files.sort()  # Optional: Sort files if needed\n",
    "\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Read the PDF file\n",
    "        reader = PdfReader(file_path)\n",
    "        \n",
    "        # Temporary memory buffer to estimate the file size\n",
    "        temp_buffer = io.BytesIO()\n",
    "\n",
    "        # Add pages individually and write to the buffer to estimate size\n",
    "        for page in reader.pages:\n",
    "            writer.add_page(page)\n",
    "            writer.write(temp_buffer)\n",
    "\n",
    "            # Check if the file size exceeds the limit\n",
    "            if temp_buffer.tell() > max_size:\n",
    "                # Finalize the current PDF and start a new one\n",
    "                writer, output_index, current_file_list = write_and_reset(writer, output_index, current_file_list)\n",
    "                # Reset buffer\n",
    "                temp_buffer = io.BytesIO()\n",
    "                # Add the current page to the new writer\n",
    "                writer.add_page(page)\n",
    "                writer.write(temp_buffer)\n",
    "\n",
    "        # Add the file to the current list after checking size\n",
    "        current_file_list.append(file_name)\n",
    "\n",
    "    # Write the last set of combined PDFs if any pages have been added\n",
    "    if len(writer.pages) > 0:\n",
    "        write_and_reset(writer, output_index, current_file_list)\n",
    "\n",
    "# Usage example\n",
    "directory_path = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/To be translated/Arabic'\n",
    "combine_pdfs_with_size_limit(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created 'combined_1.pdf' with files: ['18AlgeriaCOP24186330.pdf', '18KuwaitCOP24186437.pdf', '18OmanCOP24185051.pdf', '18TunisiaCOP24186404.pdf', '19AlgeriaCOP25204579.pdf', '19BahrainCOP25204114.pdf', '19KuwaitCOP25204061.pdf']\n",
    "Created 'combined_2.pdf' with files: ['19MoroccoCOP25204069.pdf', '21AlgeriaCOP26310802.pdf', '21KuwaitCOP26309209.pdf', '21NACOP26309286.pdf', '21OmanCOP26310839.pdf']\n",
    "Created 'combined_3.pdf' with files: ['21QatarCOP26310872.pdf', '21SyriaCOP26310880.pdf', '21TunisiaCOP26310884.pdf', '22AlgeriaCOP27622747.pdf', '22BahrainCOP27623882.pdf', '22LebanonCOP27624199.pdf', '22NACOP27623385.pdf', '22NACOP27624084.pdf', '22OmanCOP27623899.pdf', '22QatarCOP27623900.pdf', '22SudanCOP27624198.pdf', '22YemenCOP27623027.pdf', '23BahrainCOP28636641.pdf', '23KyrgyzstanCOP28636282.pdf']\n",
    "Created 'combined_4.pdf' with files: ['23LibyaCOP28636285.pdf', '23NACOP28634579.pdf', '23NACOP28635860.pdf', '23NACOP28636637.pdf', '23OmanCOP28636628.pdf', '23QatarCOP28636633.pdf', '23SyriaCOP28635631.pdf', '23TunisiaCOP28636639.pdf', '24KuwaitCOP28637243.pdf', '24SaudiArabiaCOP28637245.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make pdfs translateable txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ا\n",
      "د\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pytesseract\n",
    "import io\n",
    "\n",
    "# Enhance image for better OCR recognition\n",
    "def enhance_image(image):\n",
    "    # Convert to grayscale\n",
    "    image = image.convert('L')\n",
    "    # Increase contrast\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(2.0)\n",
    "    # Apply sharpening\n",
    "    image = image.filter(ImageFilter.SHARPEN)\n",
    "    return image\n",
    "\n",
    "def extract_text_from_pdf_image(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = []\n",
    "    \n",
    "    for page in doc:\n",
    "        image_list = page.get_images(full=True)\n",
    "        \n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            \n",
    "            # Convert image bytes to PIL Image and enhance it\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            image = enhance_image(image)\n",
    "            \n",
    "            # Use pytesseract to do OCR on the enhanced image\n",
    "            text = pytesseract.image_to_string(image, lang='ara+eng', config='--psm 6')\n",
    "            full_text.append(text)\n",
    "    \n",
    "    doc.close()\n",
    "    return full_text\n",
    "\n",
    "# Example usage\n",
    "pdf_path = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/speeches/To be translated/Arabic/18AlgeriaCOP24186330.pdf'\n",
    "text_content = extract_text_from_pdf_image(pdf_path)\n",
    "print(\"\\n\".join(text_content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change naming scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Load CSV data\n",
    "csv_path = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCCcountries.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Define the renaming schema\n",
    "rename_schema = [\n",
    "    {'column': 'classification', 'replace': {'Country_Speech': 'cs'}, 'exact': False},\n",
    "    \n",
    "    # {'column': 'Organisation/Speaker', 'replace': {}, 'exact': True},  # This column's data will be copied exactly\n",
    "    # Add more mappings here as needed\n",
    "]\n",
    "\n",
    "# Directory for renamed files\n",
    "new_directory = 'path/to/new_directory'\n",
    "os.makedirs(new_directory, exist_ok=True)\n",
    "\n",
    "def construct_new_filename(row):\n",
    "    parts = []\n",
    "    for schema in rename_schema:\n",
    "        part = row[schema['column']]\n",
    "        if not schema['exact']:\n",
    "            for key, value in schema['replace'].items():\n",
    "                part = part.replace(key, value)\n",
    "        parts.append(part)\n",
    "    return \"_\".join(parts)\n",
    "\n",
    "# Function to find the actual file regardless of extension\n",
    "def find_file(base_path, name):\n",
    "    for filename in os.listdir(base_path):\n",
    "        if os.path.splitext(filename)[0] == name:\n",
    "            return filename\n",
    "    return None\n",
    "\n",
    "# Process each file\n",
    "base_path = 'path/to/original_files'  # Update with the correct path\n",
    "for index, row in df.iterrows():\n",
    "    old_name = row['Name of Speech']\n",
    "    file_found = find_file(base_path, old_name)\n",
    "    if file_found:\n",
    "        new_name = construct_new_filename(row) + os.path.splitext(file_found)[1]  # Keep original extension\n",
    "        old_path = os.path.join(base_path, file_found)\n",
    "        new_path = os.path.join(new_directory, new_name)\n",
    "        shutil.copy2(old_path, new_path)  # Copy and rename the file\n",
    "        df.at[index, 'New_Name'] = new_name  # Add new name to the DataFrame\n",
    "    else:\n",
    "        print(f\"File corresponding to {old_name} not found.\")\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "updated_csv_path = 'path/to/your/updated_csvfile.csv'\n",
    "df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "# Note: The script now allows for copying exact column data as part of the new filename.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
