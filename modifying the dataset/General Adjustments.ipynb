{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded large CSV data.\n",
      "Identified 1 outliers in large CSV based on condition: Event == ECWIMLD12\n",
      "Outliers appended to /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/Ommitted data.csv.\n",
      "Outliers removed from large CSV data.\n",
      "Updated large CSV file saved to /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/UNFCCC.csv.\n",
      "Loaded subset CSV from /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCC_IGO.csv.\n",
      "Outliers removed from subset CSV data based on independent check.\n",
      "Updated subset CSV file saved to /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCC_IGO.csv.\n",
      "Loaded subset CSV from /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCC_NGO.csv.\n",
      "Outliers removed from subset CSV data based on independent check.\n",
      "Updated subset CSV file saved to /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCC_NGO.csv.\n",
      "Loaded subset CSV from /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCCcountries.csv.\n",
      "Outliers removed from subset CSV data based on independent check.\n",
      "Updated subset CSV file saved to /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCCcountries.csv.\n",
      "Loaded subset CSV from /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCCindependent.csv.\n",
      "Outliers removed from subset CSV data based on independent check.\n",
      "Updated subset CSV file saved to /Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCCindependent.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_outliers(large_csv_path, subset_csv_paths, condition_column, condition_value, omitted_csv_path):\n",
    "    # Load the large CSV file\n",
    "    large_data = pd.read_csv(large_csv_path)\n",
    "    print(\"Loaded large CSV data.\")\n",
    "\n",
    "    # Identify rows that meet the outlier condition in the large CSV\n",
    "    outlier_condition_large = large_data[condition_column] == condition_value\n",
    "    outliers_large = large_data[outlier_condition_large]\n",
    "    print(f\"Identified {len(outliers_large)} outliers in large CSV based on condition: {condition_column} == {condition_value}\")\n",
    "\n",
    "    # Append outliers to an existing 'omitted data' CSV file\n",
    "    outliers_large.to_csv(omitted_csv_path, mode='a', header=False, index=False)\n",
    "    print(f\"Outliers appended to {omitted_csv_path}.\")\n",
    "\n",
    "    # Remove outliers from the large CSV\n",
    "    large_data_clean = large_data[~outlier_condition_large]\n",
    "    print(\"Outliers removed from large CSV data.\")\n",
    "\n",
    "    # Update the large CSV file\n",
    "    large_data_clean.to_csv(large_csv_path, index=False)\n",
    "    print(f\"Updated large CSV file saved to {large_csv_path}.\")\n",
    "\n",
    "    # Process each subset CSV file\n",
    "    for subset_path in subset_csv_paths:\n",
    "        subset_data = pd.read_csv(subset_path)\n",
    "        print(f\"Loaded subset CSV from {subset_path}.\")\n",
    "\n",
    "        # Identify and remove outliers in the subset CSV based on the same condition applied independently\n",
    "        outlier_condition_subset = subset_data[condition_column] == condition_value\n",
    "        subset_data_clean = subset_data[~outlier_condition_subset]\n",
    "        print(\"Outliers removed from subset CSV data based on independent check.\")\n",
    "\n",
    "        # Update the subset CSV file\n",
    "        subset_data_clean.to_csv(subset_path, index=False)\n",
    "        print(f\"Updated subset CSV file saved to {subset_path}.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "large_csv_path = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/UNFCCC.csv'\n",
    "subset_csv_paths = ['/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCC_IGO.csv', '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCC_NGO.csv', '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCCcountries.csv', '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/UNFCCCindependent.csv']\n",
    "condition_column = 'Event'\n",
    "condition_value = 'ECWIMLD12'\n",
    "omitted_csv_path = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv/Subsets/Ommitted data.csv'\n",
    "\n",
    "remove_outliers(large_csv_path, subset_csv_paths, condition_column, condition_value, omitted_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy data across columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a direct match\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "directory = '/Users/calebmasters/Free From Onedrive mess/Project directory/UNFCCC_speeches/csv'\n",
    "\n",
    "# User-defined variables\n",
    "input_file = '/Subsets/UNFCCCcountries'    # The path to your CSV file\n",
    "output_file = input_file           # The path to save the updated CSV file\n",
    "condition_column = 'info' # Column to check the condition\n",
    "condition_value = 'Closing Plenary'           # Value to check for in the condition column\n",
    "target_column = 'Date'             # Column to update based on the condition\n",
    "new_value = '2023-06-13'                 # New value to set in the target column\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(f'{directory}{input_file}.csv')\n",
    "\n",
    "# Apply the condition and update the target column\n",
    "# df[target_column] = df.apply(lambda row: new_value if row[condition_column] == condition_value else row[target_column], axis=1) # for exact match\n",
    "df[target_column] = df.apply(lambda row: new_value if condition_value in str(row[condition_column]) else row[target_column], axis=1) # for containing\n",
    "\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(f'{directory}{output_file}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For containing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# User-defined variables\n",
    "input_file = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCC.csv'    # The path to your CSV file\n",
    "output_file = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCC.csv' # The path to save the updated CSV file\n",
    "condition_column = 'Name of Speech'          # Column to check the condition\n",
    "condition_value = 'GCA High-Level Event' or 'GCA HL Event'          # Substring to check for in the condition column\n",
    "target_column = 'Part of Event'             # Column to update based on the condition\n",
    "new_value = 'GCE High-Level Event'                 # New value to set in the target column\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Apply the condition and update the target column\n",
    "# Here we use 'str.contains' to check for substring presence\n",
    "df[target_column] = df.apply(lambda row: new_value if condition_value in str(row[condition_column]) else row[target_column], axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving rows between CSV's - deleting them in the origial file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For moving rows to a different CSV based on keywords\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# User-defined variables\n",
    "input_file = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/Ommitted data.csv'  # The path to your original CSV file\n",
    "output_file = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/Ommitted data copy.csv'   # The path to save the target CSV file\n",
    "columns_to_check = ['classification']  # List of columns to check for the text - can be multiple in the format `['Column1', 'Column2']`\n",
    "text_to_check = 'MP Feedback'        # Text to check for in the specified columns\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Identify rows where any specified column contains the text\n",
    "mask = df[columns_to_check].apply(lambda x: x.str.contains(text_to_check)).any(axis=1)\n",
    "selected_rows = df[mask]\n",
    "\n",
    "# Check if the output file already exists to determine if headers are needed\n",
    "if os.path.exists(output_file):\n",
    "    header = False  # Don't write headers if file already exists\n",
    "else:\n",
    "    header = True  # Write headers if file is being created\n",
    "\n",
    "# Save these rows to a new CSV file, append if file exists\n",
    "selected_rows.to_csv(output_file, mode='a', index=False, header=header)\n",
    "\n",
    "# Remove these rows from the original DataFrame\n",
    "df = df[~mask]\n",
    "\n",
    "# Save the updated original DataFrame to CSV\n",
    "df.to_csv(input_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting rows that share data with rows in a second CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete rows in a csv [`large_csv_path`] that share data with rows in a second csv [`small_csv_path`]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to your CSV files\n",
    "large_csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCC.csv'\n",
    "small_csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/Backups/Ommitted data.csv'\n",
    "\n",
    "# Load both CSV files into pandas DataFrames\n",
    "large_df = pd.read_csv(large_csv_path)\n",
    "small_df = pd.read_csv(small_csv_path)\n",
    "\n",
    "# Get the list of file names to omit from the smaller CSV\n",
    "omit_file_names = small_df['File Name'].unique()\n",
    "\n",
    "# Filter the larger DataFrame to remove rows with matching 'File Name'\n",
    "filtered_large_df = large_df[~large_df['File Name'].isin(omit_file_names)]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_large_df.to_csv('filtered_large_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling empty rows in a column with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCCcountriesonly.csv'\n",
    "output_csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCCcountriesonly.csv'\n",
    "\n",
    "# Column name and value to fill empty cells\n",
    "column_name = 'classification'  # Change this to your column name\n",
    "fill_value = 'Country_Speech'     # Change this to the value you want to fill with\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Fill empty cells in the specified column\n",
    "df[column_name] = df[column_name].fillna(fill_value)\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Larger CSV from smaller CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countries to Big CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "large_csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCC.csv'\n",
    "small_csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/Backups/UNFCCCcountriesonly.csv'\n",
    "\n",
    "# Load the CSV files\n",
    "large_df = pd.read_csv(large_csv_path)\n",
    "small_df = pd.read_csv(small_csv_path)\n",
    "\n",
    "# Set 'File Name' as the index for easier lookup and update operations\n",
    "large_df.set_index('File Name', inplace=True)\n",
    "small_df.set_index('File Name', inplace=True)\n",
    "\n",
    "# Identify the columns to update (assuming all columns in small_df except 'File Name' should be updated)\n",
    "update_columns = small_df.columns.tolist()\n",
    "\n",
    "# Update the larger DataFrame with the data from the smaller DataFrame\n",
    "for file_name in small_df.index:\n",
    "    if file_name in large_df.index:\n",
    "        large_df.loc[file_name, update_columns] = small_df.loc[file_name, update_columns]\n",
    "\n",
    "# Reset the index to bring 'File Name' back as a column\n",
    "large_df.reset_index(inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to the large CSV file\n",
    "large_df.to_csv('/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCC.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### newcalssifications to big csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "large_csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCC.csv'\n",
    "small_csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCCnewclassifications.csv'\n",
    "\n",
    "# Load the CSV files\n",
    "large_df = pd.read_csv(large_csv_path)\n",
    "small_df = pd.read_csv(small_csv_path)\n",
    "\n",
    "# Set 'File Name' as the index for easier lookup and update operations\n",
    "large_df.set_index('File Name', inplace=True)\n",
    "small_df.set_index('File Name', inplace=True)\n",
    "\n",
    "# Identify the columns to update (assuming all columns in small_df except 'File Name' should be updated)\n",
    "update_columns = small_df.columns.tolist()\n",
    "\n",
    "# Update the larger DataFrame with the data from the smaller DataFrame\n",
    "for file_name in small_df.index:\n",
    "    if file_name in large_df.index:\n",
    "        large_df.loc[file_name, update_columns] = small_df.loc[file_name, update_columns]\n",
    "\n",
    "# Reset the index to bring 'File Name' back as a column\n",
    "large_df.reset_index(inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to the large CSV file\n",
    "large_df.to_csv('/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCC.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting checked column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General template w examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting all rows\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCCcountriesonly.csv')\n",
    "\n",
    "# Set all rows in the 'checked' column to 'yes/no'\n",
    "df['checked'] = 'yes'\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df.to_csv('/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCCcountriesonly.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('')\n",
    "\n",
    "# Example 1: Fill 'checked' with 'yes' unless 'country' column contains any text\n",
    "# df['checked'] = df['country'].apply(lambda x: '' if pd.notna(x) else 'yes')\n",
    "\n",
    "# Example 2: Fill 'checked' with 'no' unless 'organisation' column exactly contains 'no organisation detected'\n",
    "df['checked'] = df['organisation'].apply(lambda x: 'no' if x != 'no organisation detected' else '')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For just countries csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCCcountriesonly.csv')\n",
    "df['checked'] = df['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting checked for empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_path = '/Users/calebmasters/Free From Onedrive mess/project directory/UNFCCC_speeches/csv/UNFCCC.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Update 'checked' to 'no' where 'classification' column is empty or NaN\n",
    "df.loc[df['classification'].isna(), 'checked'] = 'no'\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
